import json
import os
import numpy as np
import cv2
from collections import defaultdict
from segment_anything import SamPredictor, sam_model_registry

# === è¼‰å…¥æ•´åˆè³‡æ–™ ===
with open("sam_data_already_prepro_shoes.json", "r") as f:
    sam_data = json.load(f)

print(f"âœ… å…±è¼‰å…¥ {len(sam_data)} å€‹ box prompt")

# === åˆå§‹åŒ– SAM æ¨¡å‹ ===
print("ğŸ§  è¼‰å…¥ SAM æ¨¡å‹ä¸­...")
sam = sam_model_registry["vit_h"](checkpoint="sam_vit_h_4b8939.pth")
predictor = SamPredictor(sam)
print("âœ… SAM æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

# === å»ºç«‹ä¸»è¼¸å‡ºè³‡æ–™å¤¾ ===
main_output_dir = "seg_pic2_shoes"
os.makedirs(main_output_dir, exist_ok=True)
print(f"ğŸ“‚ ä¸»è¼¸å‡ºè³‡æ–™å¤¾å·²æº–å‚™å¥½ï¼š{main_output_dir}")

# === sam_data æŒ‰åœ–ç‰‡åˆ†çµ„ ===
grouped_data = defaultdict(list)
for item in sam_data:
    grouped_data[item["filename"]].append(item)

print(f"ğŸ“¸ å…±åµæ¸¬åˆ° {len(grouped_data)} å¼µåœ–ç‰‡éœ€è¦è™•ç†\n")

# === é–‹å§‹è™•ç†æ¯å¼µåœ–ç‰‡ ===
for image_idx, (filename, detections) in enumerate(grouped_data.items(), start=1):
    print(f"ğŸ”„ [{image_idx}/{len(grouped_data)}] è™•ç†åœ–ç‰‡ï¼š{filename}ï¼Œå…± {len(detections)} å€‹ç‰©ä»¶")

    image_path = os.path.join("test_image", filename)
    if not os.path.exists(image_path):
        print(f"âŒ æ‰¾ä¸åˆ°åœ–ç‰‡ï¼š{image_path}ï¼Œè·³é")
        continue

    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ åœ–ç‰‡è®€å–å¤±æ•—ï¼š{image_path}ï¼Œè·³é")
        continue

    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    predictor.set_image(image_rgb)
    print("   ğŸ§  å·²è¨­å®šåœ–ç‰‡çµ¦ SAM Predictor")

    # å»ºç«‹å­è³‡æ–™å¤¾ï¼šseg_16, seg_27, ...
    base_name = os.path.splitext(filename)[0]
    sub_output_dir = os.path.join(main_output_dir, f"seg_{base_name}")
    os.makedirs(sub_output_dir, exist_ok=True)
    print(f"   ğŸ“ å»ºç«‹å­è³‡æ–™å¤¾ï¼š{sub_output_dir}")

    # å„²å­˜åŸåœ–åˆ°å­è³‡æ–™å¤¾
    original_img_output_path = os.path.join(sub_output_dir, filename)
    cv2.imwrite(original_img_output_path, image)
    print(f"   ğŸ–¼ï¸ å·²å„²å­˜åŸåœ–ï¼š{original_img_output_path}")

    # åŒ label è¦†è“‹ç­–ç•¥ï¼šåƒ…å­˜ç¬¬ä¸€å€‹ label å°æ‡‰åœ–ç‰‡ï¼Œå‘½åç‚º label.png
    used_labels = set()

    for i, item in enumerate(detections):
        label = item["label"]
        if label in used_labels:
            print(f"      âš ï¸ label {label} å·²è™•ç†éï¼Œè·³é")
            continue
        used_labels.add(label)

        box = np.array(item["box"])
        box_input = box[None, :]  # (1, 4)

        print(f"   ğŸ¯ [{i+1}/{len(detections)}] è™•ç† label: {label}ï¼Œbox: {box.tolist()}")

        # SAM é æ¸¬é®ç½©
        masks, _, _ = predictor.predict(box=box_input, multimask_output=False)
        mask = masks[0]

        # å»ºç«‹é®ç½©å€å¡Š
        mask_3c = np.stack([mask] * 3, axis=-1)
        cutout = image_rgb * mask_3c

        # è£åˆ‡å€åŸŸ
        x0, y0, x1, y1 = box.astype(int)
        cropped = cutout[y0:y1, x0:x1]

        # å„²å­˜åœ–ç‰‡
        save_path = os.path.join(sub_output_dir, f"{label}.png")
        cropped_bgr = cv2.cvtColor(cropped, cv2.COLOR_RGB2BGR)
        success = cv2.imwrite(save_path, cropped_bgr)

        if success:
            print(f"      âœ… å·²å„²å­˜ï¼š{save_path}")
        else:
            print(f"      âŒ å„²å­˜å¤±æ•—ï¼š{save_path}")

    print(f"   âœ… åœ–ç‰‡ {filename} è™•ç†å®Œæˆ\n")

print("ğŸ‰ å…¨éƒ¨åœ–ç‰‡è™•ç†å®Œç•¢ï¼æ‰€æœ‰åˆ‡å‰²åœ–èˆ‡åŸåœ–å·²è¼¸å‡ºåˆ°ï¼š", main_output_dir)
