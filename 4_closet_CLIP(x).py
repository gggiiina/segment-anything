import os
import torch
import clip
from PIL import Image
import json

# === åˆå§‹åŒ– CLIP æ¨¡å‹ ===
print("ğŸ§  è¼‰å…¥ CLIP æ¨¡å‹ä¸­...")
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)
print(f"âœ… CLIP æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œä½¿ç”¨è£ç½®ï¼š{device}")

closet_dir = "closet"
output_json = "closet_clip_features.json"
closet_features = {}

# === å–å¾—åœ–ç‰‡åˆ—è¡¨ ===
image_files = [f for f in os.listdir(closet_dir) if f.lower().endswith((".jpg", ".png", ".jpeg"))]
print(f"ğŸ§¾ å…±æ‰¾åˆ° {len(image_files)} å¼µåœ–ç‰‡è¦è™•ç†")

# === è™•ç†æ¯å¼µåœ–ç‰‡ ===
for idx, fname in enumerate(image_files, start=1):
    image_path = os.path.join(closet_dir, fname)
    print(f"ğŸ”„ [{idx}/{len(image_files)}] è™•ç†åœ–ç‰‡ï¼š{fname}")

    try:
        image = preprocess(Image.open(image_path).convert("RGB")).unsqueeze(0).to(device)

        with torch.no_grad():
            feature = model.encode_image(image).cpu().numpy()[0]

        key = os.path.splitext(fname)[0]
        closet_features[key] = {
            "filename": fname,
            "feature": feature.tolist()
        }

        print(f"   âœ… å‘é‡å·²æŠ½å–ï¼Œå„²å­˜ keyï¼š{key}")

    except Exception as e:
        print(f"   âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}ï¼Œç•¥éæ­¤åœ–")

# === å„²å­˜ JSON ===
with open(output_json, "w") as f:
    json.dump(closet_features, f)

print(f"\nğŸ‰ å…¨éƒ¨è™•ç†å®Œç•¢ï¼å…±å„²å­˜ {len(closet_features)} ç­†å‘é‡")
print(f"ğŸ“ ç‰¹å¾µæª”æ¡ˆå·²å„²å­˜è‡³ï¼š{output_json}")
