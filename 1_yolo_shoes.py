import os
import torch
import json
from PIL import Image, ImageDraw, ImageFont
from transformers import AutoImageProcessor, AutoModelForObjectDetection


def detect_fashion_items(
    input_path,
    output_json_path="sam_data.json",
    output_image_dir="output_vis",
    conflict_rules_path="yolo_conflict_rules.json",
    show_image=False,
    save_image=False,
    min_confidence=0.5
):
    print("ğŸš€ åˆå§‹åŒ– YOLOS æ¨¡å‹ä¸­...")
    processor = AutoImageProcessor.from_pretrained("valentinafeve/yolos-fashionpedia")
    model = AutoModelForObjectDetection.from_pretrained("valentinafeve/yolos-fashionpedia")
    print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")

    try:
        font = ImageFont.truetype("arial.ttf", 20)
    except:
        font = ImageFont.load_default()

    target_ids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 23]
    all_sam_data = []

    # âœ… è¼‰å…¥è¡çªè¦å‰‡
    if os.path.exists(conflict_rules_path):
        with open(conflict_rules_path, "r") as f:
            conflict_rules = json.load(f)
    else:
        conflict_rules = {}

    # âœ… è™•ç†åœ–åƒä¾†æº
    if os.path.isdir(input_path):
        image_files = [os.path.join(input_path, f) for f in os.listdir(input_path)
                       if f.lower().endswith((".jpg", ".jpeg", ".png"))]
    elif os.path.isfile(input_path):
        image_files = [input_path]
    else:
        raise ValueError(f"âŒ æ‰¾ä¸åˆ°æŒ‡å®šè·¯å¾‘ï¼š{input_path}")
    print(f"ğŸ“‚ åµæ¸¬åˆ° {len(image_files)} å¼µåœ–ç‰‡è¦è™•ç†...\n")

    if save_image and not os.path.exists(output_image_dir):
        os.makedirs(output_image_dir)

    for idx, image_path in enumerate(image_files, 1):
        filename = os.path.basename(image_path)
        print(f"\nğŸ–¼ï¸ [{idx}/{len(image_files)}] è™•ç†åœ–ç‰‡ï¼š{filename}")
        image = Image.open(image_path).convert("RGB")
        draw = ImageDraw.Draw(image)
        inputs = processor(images=image, return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)
        target_sizes = torch.tensor([image.size[::-1]])
        results = processor.post_process_object_detection(outputs, threshold=0.0, target_sizes=target_sizes)[0]

        # === ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ‰€æœ‰å€™é¸é …ç›®ï¼ˆç¬¦åˆ label å’Œ min_confidenceï¼‰
        all_candidates = []
        for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
            label_id = int(label.item())
            score_val = float(score.item())

            if label_id not in target_ids:
                continue
            if score_val < min_confidence:
                continue

            label_name = model.config.id2label.get(label_id, f"id_{label_id}")
            all_candidates.append({
                "label_id": label_id,
                "score": score_val,
                "box": box,
                "label_name": label_name
            })

        # === ç¬¬äºŒæ­¥ï¼šä¾ score é™å†ªæ’åº
        all_candidates.sort(key=lambda x: x["score"], reverse=True)

        # === ç¬¬ä¸‰æ­¥ï¼šä¾åºæª¢æŸ¥è¡çªè¦å‰‡ä¾†æ±ºå®šä¿ç•™å“ªäº›é …ç›®
        best_detections = {}
        shoe_candidates = []

        for cand in all_candidates:
            label_id = cand["label_id"]
            score_val = cand["score"]
            box = cand["box"]
            label_name = cand["label_name"]

            print(f"ğŸ” å˜—è©¦åŠ å…¥ï¼š{label_name}ï¼ˆID: {label_id}, åˆ†æ•¸: {score_val:.2f}ï¼‰")

            # æª¢æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒçš„ label
            if label_id in best_detections:
                existing_score = best_detections[label_id][0]
                if score_val > existing_score:
                    print(f"  âš ï¸ å·²æœ‰ç›¸åŒæ¨™ç±¤ï¼Œä½†åˆ†æ•¸è¼ƒé«˜ï¼Œå–ä»£åŸæœ‰é …ç›®")
                    best_detections[label_id] = (score_val, box, label_name)
                else:
                    print(f"  âš ï¸ å·²æœ‰ç›¸åŒæ¨™ç±¤ï¼Œåˆ†æ•¸è¼ƒä½ï¼Œè·³éæ­¤é …ç›®")
                continue

            # æª¢æŸ¥è¡çª
            conflict_with = None
            for existing_id in best_detections.keys():
                conflict_ids = conflict_rules.get(str(existing_id), [])
                if str(label_id) in conflict_ids:
                    conflict_with = existing_id
                    break

            if conflict_with is not None:
                # æ¯”è¼ƒåˆ†æ•¸ï¼Œä¿ç•™åˆ†æ•¸é«˜çš„
                existing_score = best_detections[conflict_with][0]
                if score_val > existing_score:
                    print(f"  âš ï¸ èˆ‡å·²é¸æ“‡çš„ {conflict_with} ç™¼ç”Ÿè¡çªï¼Œä½†åˆ†æ•¸è¼ƒé«˜ï¼Œå–ä»£åŸæœ‰é …ç›®")
                    del best_detections[conflict_with]
                else:
                    print(f"  âš ï¸ èˆ‡å·²é¸æ“‡çš„ {conflict_with} ç™¼ç”Ÿè¡çªï¼Œåˆ†æ•¸è¼ƒä½ï¼Œè·³éæ­¤é …ç›®")
                    continue

            # è™•ç†é‹å­ç‰¹æ®Šé‚è¼¯
            if label_id == 23:
                shoe_candidates.append((score_val, box))
                print(f"  âœ… æ˜¯é‹å­ï¼Œæš«å­˜èµ·ä¾†å‚™ç”¨")
            else:
                best_detections[label_id] = (score_val, box, label_name)
                print(f"  âœ… åŠ å…¥ best_detectionsï¼š{label_name}")


        # âœ… åˆä½µå…©éš»é‹å­
        shoe_candidates.sort(reverse=True, key=lambda x: x[0])
        if len(shoe_candidates) >= 2:
            _, box1 = shoe_candidates[0]
            _, box2 = shoe_candidates[1]
            x1 = min(box1[0], box2[0])
            y1 = min(box1[1], box2[1])
            x2 = max(box1[2], box2[2])
            y2 = max(box1[3], box2[3])
            merged_box = torch.tensor([x1, y1, x2, y2])
            best_detections[23] = (1.0, merged_box, "shoe")
            print(f"ğŸ‘Ÿ åˆä½µé‹å­æˆåŠŸï¼ŒåŠ å…¥ best_detections")

        print("\nğŸ“Œ æœ¬å¼µåœ–çš„ best_detections çµæœï¼š")
        for k, (score_val, _, label_name) in best_detections.items():
            print(f"  - {label_name}ï¼ˆID: {k}, åˆ†æ•¸: {score_val:.2f}ï¼‰")

        for label_id, (score_val, box_tensor, label_name) in best_detections.items():
            box = [round(i, 2) for i in box_tensor.tolist()]
            text = f"{label_name} ({round(score_val, 2)})"
            bbox = font.getbbox(text)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            draw.rectangle(box, outline="red", width=3)
            draw.rectangle(
                [box[0], max(0, box[1] - text_height - 10), box[0] + text_width + 4, box[1]],
                fill="red"
            )
            draw.text((box[0] + 2, box[1] - text_height - 5), text, fill="white", font=font)
            all_sam_data.append({
                "filename": filename,
                "label": label_name,
                "box": box
            })

        if save_image:
            save_path = os.path.join(output_image_dir, filename)
            image.save(save_path)
            print(f"ğŸ’¾ å·²å„²å­˜ï¼š{save_path}")

        if show_image:
            image.show()

    with open(output_json_path, "w") as f:
        json.dump(all_sam_data, f, indent=2)
    print(f"\nğŸ‰ åµæ¸¬å®Œæˆï¼Œè³‡æ–™å·²å„²å­˜ï¼š{output_json_path}")

    return all_sam_data


# âœ… åŸ·è¡Œç¯„ä¾‹
detect_fashion_items(
    input_path="test_image",
    output_json_path="sam_data.json",
    output_image_dir="output_yolo",
    conflict_rules_path="yolo_conflict_rules.json",
    show_image=False,
    save_image=True,
    min_confidence=0.05,
)
